# Mejoras Futuras

Documento de funcionalidades a implementar en el futuro.

---

## Prioridad Cr√≠tica

### 1. Sistema de Experiencia y Niveles

**Prioridad**: Cr√≠tica  
**Complejidad**: Alta

Sin esto, el PJ nunca progresa. Es el coraz√≥n de D&D y afecta a todo lo dem√°s:
- Umbrales de XP por nivel
- Subida de nivel autom√°tica
- Nuevos rasgos de clase por nivel
- Aumento de caracter√≠sticas (ASI)
- Nuevas ranuras de conjuros

### 2. M√°s Clases Base

**Prioridad**: Cr√≠tica  
**Complejidad**: Media

Actualmente solo est√°n implementadas **4 clases**:
- ‚úÖ Guerrero
- ‚úÖ P√≠caro  
- ‚úÖ Mago
- ‚úÖ Cl√©rigo

Faltan las 8 restantes del SRD:
- ‚ùå B√°rbaro
- ‚ùå Bardo
- ‚ùå Druida
- ‚ùå Monje
- ‚ùå Palad√≠n
- ‚ùå Explorador (Ranger)
- ‚ùå Hechicero
- ‚ùå Brujo

---

## Prioridad Alta

### 3. Normalizaci√≥n de Input con LLM

**Prioridad**: Alta  
**Complejidad**: Media

Convertir lenguaje natural del jugador a acciones estructuradas:
- "rematar al herido" ‚Üí atacar al enemigo con menos HP
- "el m√°s cercano" ‚Üí resolver referencia al contexto
- "usar mi varita" ‚Üí buscar varita en inventario y activarla

Ver secci√≥n detallada m√°s abajo.

### 4. Sistema de Magia Completo

**Prioridad**: Alta  
**Complejidad**: Alta

- Ranuras de conjuros por nivel
- Componentes (verbal, som√°tico, material)
- Concentraci√≥n
- Todos los conjuros del SRD

### 5. IA de Enemigos Mejorada

**Prioridad**: Alta  
**Complejidad**: Media

- T√°cticas basadas en tipo de criatura
- Selecci√≥n inteligente de objetivos
- Uso de habilidades especiales

---

## Prioridad Media

### 6. Condiciones de Estado

- Envenenado, paralizado, cegado, aturdido, etc.
- Efectos mec√°nicos correctos seg√∫n las reglas

### 7. Movimiento T√°ctico

- Grid de combate (opcional)
- Ataques de oportunidad
- Terreno dif√≠cil

### 8. Descansos

- Descanso corto (dados de golpe)
- Descanso largo (recuperar todo)

---

### 9. Optimizaci√≥n de Prompt para Modelos 32B

**Prioridad**: Baja  
**Complejidad**: Media

Para funcionar bien con modelos m√°s peque√±os (32B), el prompt necesitar√≠a optimizaciones:

#### Reducir tokens del System Prompt

| Versi√≥n | Tokens | Uso |
|---------|--------|-----|
| Actual (70B+) | ~5,500 | Muy detallado |
| Lite (32B) | ~2,500-3,000 | Solo lo esencial |

#### Simplificar formato JSON

```python
# Actual (modelo grande)
{"herramienta": "iniciar_combate", "parametros": {"enemigos": ["goblin"]}, 
 "narrativa": "...", "cambio_modo": "combate", "memoria": {...}}

# Lite (modelo 32B)
{"h": "iniciar_combate", "e": ["goblin"], "n": "Narraci√≥n breve..."}
```

#### Instrucciones m√°s directas

- Quitar ejemplos redundantes
- Eliminar reglas obvias
- Menos secciones, m√°s conciso

#### Perfil LLM "lite"

A√±adir en `llm_profiles.json`:
```json
"lite": {
  "prompt_mode": "reducido",
  "max_tokens": 400,
  "descripcion": "Para modelos 32B o menores"
}
```

#### Tama√±os de modelo recomendados

| Tama√±o | Calidad DM | Notas |
|--------|------------|-------|
| 7-8B | ‚ö†Ô∏è B√°sico | Narrativa limitada |
| 12-14B | üü° Aceptable | A veces olvida contexto |
| 32-40B | üü¢ Bueno | Funciona bien con prompt optimizado |
| 70-80B | ‚≠ê Excelente | Recomendado, prompt actual |

---

## Prioridad Baja / Futuro

- Interfaz web
- Multijugador
- Importar personajes de D&D Beyond
- Integraci√≥n con VTTs (Roll20, Foundry)

---

## Optimizaciones de Rendimiento LLM

### KV Cache para System Prompt

**Estado**: Implementado (parcialmente funcional seg√∫n modelo)  
**Fecha**: 2026-01-11

#### Contexto

El framework env√≠a ~5500 tokens de system prompt en cada turno al LLM. Esto incluye:
- Instrucciones del DM (~3000 tokens)
- Herramientas disponibles (~500 tokens)
- Adventure Bible (~800 tokens)
- Prompt de tono (~400 tokens)
- Contexto actual del PJ (~800 tokens)

#### Optimizaci√≥n Implementada

Se reorganiz√≥ el system prompt en `dm_cerebro.py` para poner el contenido **est√°tico primero** y el **din√°mico al final**:

```python
def _construir_system_prompt(self) -> str:
    """
    OPTIMIZACI√ìN KV CACHE: Contenido ordenado de m√°s est√°tico a m√°s din√°mico.
    
    Orden:
    1. EST√ÅTICO: Instrucciones base del DM (nunca cambia)
    2. EST√ÅTICO: Herramientas disponibles (nunca cambia)
    3. SEMI-EST√ÅTICO: Adventure Bible (cambia entre actos)
    4. SEMI-EST√ÅTICO: Prompt de tono (cambia si cambia aventura)
    5. DIN√ÅMICO: Contexto actual (cambia cada turno)
    """
```

#### Resultados por Modelo

| Modelo | KV Cache | Tokens a Procesar | Tiempo Prompt |
|--------|----------|-------------------|---------------|
| **Llama-3.3-70B GGUF** | ‚úÖ Funciona | ~700 (12%) | ~3-4s |
| **Qwen3-Next-80B-A3B GGUF** | ‚ùå Falla* | ~5500 (100%) | ~12s |
| **Modelos MLX** | ‚ùå No soportado | ~5500 (100%) | ~9s |

*El modelo detecta cach√© pero falla al aplicarlo: `Failed to remove tokens from cache, clearing cache instead.` Probablemente por ser MoE (Mixture of Experts).

#### Pr√≥ximos Pasos

1. **Probar Qwen2.5-72B GGUF** (no es MoE, deber√≠a funcionar)
2. **Esperar actualizaciones de llama.cpp** para soporte MoE
3. **Monitorear actualizaciones de LM Studio**

#### C√≥mo Verificar si Funciona

En los logs de LM Studio, buscar:
```
‚úÖ FUNCIONA:
Cache reuse summary: 5052/5749 of prompt (87%)
Prompt tokens to decode: 697  ‚Üê Solo estos nuevos

‚ùå NO FUNCIONA:
Failed to remove tokens from cache, clearing cache instead.
Prompt tokens to decode: 5749  ‚Üê Todos
```

---

### Formas de Aprovechar M√°s Contexto

Con 32K-65K tokens disponibles, podr√≠as hacer esto:

1. Historial M√°s Largo (actualmente ~15 turnos)

- Ahora:     √öltimos 15 turnos (~1,500 tokens)
- Posible:   √öltimos 50-100 turnos (~5,000-10,000 tokens)
- Beneficio: El DM recuerda todo lo que pas√≥ en la sesi√≥n

2. Resumen de Sesiones Anteriores

Nueva secci√≥n en el prompt:
"RESUMEN SESIONES PREVIAS:
 - Sesi√≥n 1: Llegaste a Neverwinter, conociste a Marta
 - Sesi√≥n 2: Descubriste el culto de Shar en la taberna
 - Sesi√≥n 3: Perseguiste a la sombra hasta las catacumbas"

3. Adventure Bible Completa (no filtrada)

- Ahora:     Solo vista del acto actual (~800 tokens)
- Posible:   Toda la Bible (~3,000-5,000 tokens)
- Beneficio: El DM conoce TODO el plot, no solo el acto actual

4. Memoria de NPCs Rica

- Ahora:     Solo NPCs en escena
- Posible:   Historial completo de cada NPC encontrado
           "Marta: encontrada turno 5, actitud amistosa, te dio info..."



### Mejora Propuesta: Historial como Mensajes Separados

**Estado**: Pendiente de implementaci√≥n  
**Prioridad**: Media  
**Impacto**: Alto para rendimiento de KV cache

#### Problema Actual

El historial de turnos se incluye **dentro** del system prompt como texto:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ SYSTEM PROMPT (cambia cada turno)                           ‚îÇ
‚îÇ ‚Ä¢ Instrucciones DM (fijo)                                   ‚îÇ
‚îÇ ‚Ä¢ Bible (semi-fijo)                                         ‚îÇ
‚îÇ ‚Ä¢ Historial de turnos (DIN√ÅMICO) ‚Üê Rompe el cache           ‚îÇ
‚îÇ ‚Ä¢ Contexto PJ (din√°mico)                                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ USER: "ataco al goblin"                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

Cada turno el system prompt cambia, invalidando el KV cache.

#### Soluci√≥n Propuesta

Mover el historial a **mensajes user/assistant separados**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ SYSTEM PROMPT (FIJO - 100% cacheable)                       ‚îÇ
‚îÇ ‚Ä¢ Instrucciones DM                                          ‚îÇ
‚îÇ ‚Ä¢ Bible                                                     ‚îÇ
‚îÇ ‚Ä¢ Reglas                                                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ USER: "entro en la taberna"                                 ‚îÇ
‚îÇ ASSISTANT: "La taberna huele a cerveza..."                  ‚îÇ
‚îÇ USER: "hablo con el tabernero"                              ‚îÇ
‚îÇ ASSISTANT: "El tabernero te mira con desconfianza..."       ‚îÇ
‚îÇ ...                                                         ‚îÇ
‚îÇ USER: "ataco al goblin" ‚Üê Mensaje actual                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Beneficios

- System prompt 100% cacheable
- KV cache se reutiliza completamente
- Tiempo de procesamiento reducido significativamente

#### Cambios Necesarios

1. Modificar `dm_cerebro.py`:
   ```python
   def _llamar_llm(self, mensaje_usuario: str) -> str:
       # Separar mensajes en lugar de un solo system prompt
       messages = [
           {"role": "system", "content": self._system_prompt_fijo()},
           *self._historial_como_mensajes(),  # Lista de user/assistant
           {"role": "user", "content": mensaje_usuario}
       ]
   ```

2. Modificar `llm/__init__.py`:
   - Aceptar lista de mensajes en lugar de solo system+user

3. Modificar `contexto.py`:
   - Separar historial del contexto embebido

---

### Aprovechamiento del Contexto Largo

**Estado**: No implementado (investigaci√≥n)  
**Contexto disponible**: Hasta 131K tokens con modelos modernos

#### Uso Actual vs Potencial

| Elemento | Uso Actual | Uso Potencial |
|----------|------------|---------------|
| System prompt base | ~3,000 tokens | ~3,000 tokens (fijo) |
| Adventure Bible | ~800 tokens | ~3,000-5,000 tokens (completa) |
| Historial | ~15 turnos (~1,500 tokens) | ~50-100 turnos (~5,000-10,000 tokens) |
| Resumen sesiones | ‚ùå No existe | ~1,000-2,000 tokens |
| Memoria NPCs | Solo escena actual | Historial completo (~1,000 tokens) |
| **Total** | **~5,500 tokens** | **~15,000-20,000 tokens** |

#### Mejoras Posibles

1. **Historial m√°s largo** (f√°cil):
   - Cambiar l√≠mite de turnos de 15 a 50-100
   - El DM recuerda todo lo de la sesi√≥n actual

2. **Resumen de sesiones anteriores** (medio):
   - Al terminar sesi√≥n, guardar resumen LLM
   - Al cargar, incluir res√∫menes previos
   - Ejemplo: "Sesi√≥n 1: Llegaste a Neverwinter, conociste a Marta..."

3. **Adventure Bible completa** (f√°cil):
   - No filtrar por acto actual
   - El DM conoce todo el plot, mejora coherencia

4. **Memoria de NPCs persistente** (medio):
   - Guardar historial de cada NPC encontrado
   - Incluir actitudes, interacciones previas

#### Recomendaci√≥n de Contexto LM Studio

| Uso | Contexto Recomendado | RAM KV Cache |
|-----|---------------------|--------------|
| Solo D&D actual | 16,384 tokens | ~2-3 GB |
| Con mejoras | 32,768 tokens | ~4-6 GB |
| M√°ximo aprovechamiento | 65,536 tokens | ~8-12 GB |
| Overkill (sin beneficio) | 131,072 tokens | ~16-24 GB |

---

## Streaming de Respuestas LLM

**Estado**: Parcialmente implementado  
**Fecha**: 2026-01-11

### Lo Implementado

1. **Efecto typewriter en narrativa** (`cli_aventura.py`):
   - El texto aparece letra a letra con `velocidad=0.02s` por car√°cter
   - Hace la lectura m√°s amena mientras esperas

2. **Funci√≥n de streaming en API** (`llm/__init__.py`):
   - `llamar_llm_streaming()` con callback `on_token`
   - Preparado para streaming real si se cambia la arquitectura

### Limitaci√≥n Actual

El DM responde en JSON que necesita parsearse completo antes de mostrar la narrativa. El streaming "real" (mostrar mientras genera) requerir√≠a:
1. Que el LLM genere la narrativa primero, herramientas despu√©s
2. O cambiar el formato de respuesta completamente

El efecto typewriter es un buen compromiso que mejora la experiencia sin cambiar la arquitectura.

---

## Detalle: Normalizaci√≥n de Acciones de Combate con LLM

### Estado Actual

El sistema de combate usa un normalizador basado en patrones de texto (`normalizador.py`) que solo reconoce verbos espec√≠ficos:
- ‚úÖ `ataco`, `golpeo`, `disparo`, `lanzo`
- ‚úÖ `mover`, `muevo`, `corro`
- ‚ùå `rematar`, `acabar con`, `eliminar`
- ‚ùå Referencias como "el herido", "el m√°s cercano"

### Flujo Propuesto

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  JUGADOR: "intento rematar al esqueleto herido"                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PASO 1: LLM Normaliza                                          ‚îÇ
‚îÇ  Input: texto natural + contexto (enemigos, HPs, etc.)          ‚îÇ
‚îÇ  Output: JSON can√≥nico {"accion": "ataque", "objetivo": "..."}  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PASO 2: Motor de Combate Resuelve                              ‚îÇ
‚îÇ  - Tiradas de dado                                              ‚îÇ
‚îÇ  - C√°lculo de da√±o                                              ‚îÇ
‚îÇ  - Aplicaci√≥n de efectos                                        ‚îÇ
‚îÇ  Output: eventos mec√°nicos                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PASO 3: LLM Narra                                              ‚îÇ
‚îÇ  Input: eventos mec√°nicos + contexto                            ‚îÇ
‚îÇ  Output: narraci√≥n inmersiva                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Cambios T√©cnicos Necesarios

1. **Nuevo m√©todo en `NormalizadorAcciones`**:
   ```python
   def normalizar_con_llm(self, texto: str, contexto: ContextoEscena) -> AccionNormalizada:
       prompt = self._construir_prompt_normalizacion(texto, contexto)
       respuesta = self._llm_callback(prompt)
       return self._parsear_respuesta_llm(respuesta)
   ```

2. **Integraci√≥n en `OrquestadorCombate.procesar_turno_jugador()`**:
   - Intentar normalizaci√≥n con patrones primero (r√°pido)
   - Si falla, usar LLM como fallback
   - Cachear normalizaciones frecuentes

---

*√öltima actualizaci√≥n: 2026-01-11*
